{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Titanic \u2014 Model Training Notebook\n",
        "\n",
        "This notebook loads the Titanic dataset (from `../data/dataset.csv`), performs basic EDA, trains multiple models, compares them with cross-validation, selects the best model, and saves it to `../model.pkl`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "DATA_PATH = '../data/dataset.csv'\n",
        "TARGET_COL = 'Survived'\n",
        "CAT_COLS = ['Sex', 'Pclass', 'Embarked']\n",
        "NUM_COLS = ['Age', 'SibSp', 'Parch', 'Fare']\n",
        "\n",
        "assert os.path.exists(DATA_PATH), f'Missing data at {DATA_PATH}. Put Titanic CSV there.'\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic EDA\n",
        "print(df.shape)\n",
        "df.info()\n",
        "df.describe(include='all')\n",
        "sns.countplot(data=df, x='Sex', hue='Survived')\n",
        "plt.title('Survival by Sex')\n",
        "plt.show()\n",
        "sns.countplot(data=df, x='Pclass', hue='Survived')\n",
        "plt.title('Survival by Pclass')\n",
        "plt.show()\n",
        "sns.histplot(df, x='Age', hue='Survived', kde=True, bins=30)\n",
        "plt.title('Age Distribution by Survival')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocess + models\n",
        "numeric_tf = Pipeline([\n",
        "    ('impute', SimpleImputer(strategy='median')),\n",
        "    ('scale', StandardScaler())\n",
        "])\n",
        "categorical_tf = Pipeline([\n",
        "    ('impute', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "pre = ColumnTransformer([\n",
        "    ('num', numeric_tf, NUM_COLS),\n",
        "    ('cat', categorical_tf, CAT_COLS)\n",
        "])\n",
        "\n",
        "models = {\n",
        "    'LogisticRegression': Pipeline([('pre', pre), ('clf', LogisticRegression(max_iter=1000))]),\n",
        "    'RandomForest': Pipeline([('pre', pre), ('clf', RandomForestClassifier(n_estimators=300, random_state=42))]),\n",
        "    'SVM': Pipeline([('pre', pre), ('clf', SVC(probability=True, kernel='rbf', C=1.0, gamma='scale', random_state=42))])\n",
        "}\n",
        "\n",
        "X = df[CAT_COLS + NUM_COLS]\n",
        "y = df[TARGET_COL].astype(int)\n",
        "\n",
        "scores = {name: float(np.mean(cross_val_score(pipe, X, y, cv=5, scoring='accuracy'))) for name, pipe in models.items()}\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_name = max(scores, key=scores.get)\n",
        "best_model = models[best_name]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "best_model.fit(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "acc, cm, report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model to project root\n",
        "joblib.dump(best_model, '../model.pkl')\n",
        "with open('../artifacts/metrics.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump({'cv_scores': scores, 'best_model': best_name, 'holdout_accuracy': float(acc), 'confusion_matrix': cm.tolist()}, f, indent=2)\n",
        "print('Saved model to ../model.pkl')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}